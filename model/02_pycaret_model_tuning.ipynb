{"cells":[{"cell_type":"markdown","metadata":{"id":"P4kIqxWOPPHW"},"source":["# Pycaret with Google Colab\n","\n","## Contents:\n","- Part 1: Cleaning and Visualization\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1biEgivJEOUVS8KbeTXyb1lNgsVtbitYj)\n","\n","- Part 2: Using PyCaret for Model Hyperparameters Tuning\n","  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lXJhdH3rGnKQ_LjBGMh8ZK-Lf2VcfLW5)\n","- Part 3: Create Model\n","  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14XIC90Lss_izdw-PE1cgIe4eECsXrHbY)\n","\n","\n","\n","I couldn't install PyCaret and many libraries on my machine (Macbook Air M1), and it is hard to fix, so I decided to use PyCaret libraries on Google Colab instead and it's easier to share with the others to understand the work."]},{"cell_type":"markdown","metadata":{"id":"xq-1E48WP08O"},"source":["## Preparation \n","\n","Install important variables and import to the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0WTTXxmcIsr"},"outputs":[],"source":["# Install pycaret from source for further information. Please check at: https://github.com/pycaret/pycaret\n","import numpy as np\n","!pip install pycaret[full]==2.3.10 markupsafe==2.0.1 pyyaml==5.4.1 -qq\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxxIDF25bzrG"},"outputs":[],"source":["# Import libraries\n","!pip install -U matplotlib\n","import numpy as np\n","from pycaret.utils import enable_colab # enable Pycaret on Colab\n","import pandas as pd\n","import jinja2\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import xgboost\n","from pycaret.regression import *\n","enable_colab()"]},{"cell_type":"markdown","metadata":{"id":"xaaLsk3VnIk8"},"source":["### Import Data\n","\n","Get the data from my Google Drive. You could check at: [MyGithub](https://github.com/northpr/GermanyRentalPrice)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2N2xzABQvzb"},"outputs":[],"source":["!gdown --id 1yw4RN-Z9b7PlF45kC5HnXZokaXivk3EV\n","\n","predict_df = pd.read_csv('predict_test.csv').iloc[:,1:]\n"]},{"cell_type":"markdown","metadata":{"id":"hcnfVVukP-mh"},"source":["# Basic inspection\n","Checking the data before continuing my work to make sure that's everything is on the right track"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7ccYgsweOVP"},"outputs":[],"source":["# Dataframe that I want to use in my prediction\n","predict_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmh1dUDPRcai"},"outputs":[],"source":["print(f\"Number of the dataframe: {predict_df.shape[0]}\")"]},{"cell_type":"markdown","metadata":{"id":"GCsRrsktriW5"},"source":["# Start using PyCaret on the df\n","I will use all of the variables from the 'predict_df'.\n","You could check how to use PyCaret Tutorial on how to preparation at: [PyCaret Tutorials](https://pycaret.gitbook.io/docs/get-started/tutorials)\n","\n","Use only basic variables that has a high correlation to the prediction and the easiest choice for the users to get those variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO-LFNeop2-3"},"outputs":[],"source":["p_data = predict_df.sample(frac=0.9, random_state=123)\n","p_data_unseen = predict_df\n","\n","p_data.reset_index(drop=True, inplace=True)\n","p_data_unseen.reset_index(drop=True, inplace=True)\n","\n","print('Data for Modeling: ' + str(p_data.shape))\n","print('Unseen Data For Predictions ' + str(p_data_unseen.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0yFKaSdrub1"},"outputs":[],"source":["p_data.head()"]},{"cell_type":"markdown","metadata":{"id":"thBdY3vPcrUV"},"source":["### Setting up the PyCaret on prediction data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgTaXdV6ryhE"},"outputs":[],"source":["import jinja2\n","from pycaret.regression import *\n","\n","# Setup the data and choose the target for the model.\n","exp_reg101 = setup(data = p_data, target = 'totalRent', session_id=123, \n","                   normalize = True, silent = True, combine_rare_levels = True, rare_level_threshold = 0.05,\n","                   remove_multicollinearity = True, multicollinearity_threshold=0.95,experiment_name='experiment_1') "]},{"cell_type":"markdown","metadata":{"id":"4SCZASM7f5ky"},"source":["Exclude model that I don't concern to use in this dataframe due to the complexity of the models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KELGeXsrzE0"},"outputs":[],"source":["# Might take around 10-12 mins due to the complexity of Extreme Gradient Boost and CatBoost\n","best = compare_models(exclude = ['ransac','rf','ada','et','huber','knn','par','omp','dt','en'], n_select=3)"]},{"cell_type":"markdown","metadata":{"id":"rYX5-IvoXSAR"},"source":["## CatBoost Regressor"]},{"cell_type":"markdown","metadata":{"id":"zMbrx-yKXSAX"},"source":["From the table of model comparing above we could see that CatBoost Regressor gives the best result by inspect on MAE, RMSE and R2. So we should consider this model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saYhAdYaXSAX"},"outputs":[],"source":["catboost_para = create_model('catboost', round=2)\n","print(catboost_para)"]},{"cell_type":"code","source":["print(catboost_para)"],"metadata":{"id":"1XxQm7Q4aLl-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpZJb2fyXSAX"},"source":["### Hyperparameter Tuning\n","Tunes the 'CatBoost' model. The output of this function is a score grid with CV scores by fold of the best selected model based on optimize parameter.\n","\n","[PyCaret: tune_model](https://pycaret.readthedocs.io/en/latest/api/regression.html#pycaret.regression.tune_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Vs_09pnXSAX"},"outputs":[],"source":["tuned_catboost = tune_model(catboost_para)\n","print(tuned_catboost)"]},{"cell_type":"code","source":["tuned_catboost"],"metadata":{"id":"oTjfu9jJahbm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A4rn7mr_itLr"},"source":["### Visualization\n","From the plot below, we know that the 'CatBoost' considers numerical variables (Living Space, Addition Cost, and No. of Rooms) more important than categorical variables (City, Heating Type, and Room Condition)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaSa5SEMitLw"},"outputs":[],"source":["plot_model(tuned_catboost, plot='feature_all')"]},{"cell_type":"markdown","metadata":{"id":"H9GQz6d0X3pm"},"source":["## Extreme Gradient Boosting"]},{"cell_type":"markdown","metadata":{"id":"23nN_w6nX3pn"},"source":["Extreme Gradient Boosting or xgboost is a model that always gives the best result by inspect on MAE, RMSE and R2. So we should keep consider this model for further use."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMdVnHLFX3pn"},"outputs":[],"source":["xgboost_para = create_model('xgboost', round=2)\n","print(xgboost_para)"]},{"cell_type":"markdown","metadata":{"id":"IUuCR03flv19"},"source":["### Visualization\n","From the plot below, we know that the 'Light Gradient Boosting Machine' considers numerical variables (Living Space, Addition Cost, and No. of Rooms) more important than categorical variables (City, Heating Type, and Room Condition)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCaZa-Q_lv2F"},"outputs":[],"source":["plot_model(xgboost_para, plot='feature_all')"]},{"cell_type":"markdown","metadata":{"id":"QsHtYJljlv2F"},"source":["Living Space, Addition Cost and Number of Rooms are the most important so we can make a conclusion that numerical are more important than catgorical variables for Light Gradient Boost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zKGWJR9lv2F"},"outputs":[],"source":["plot_model(xgboost_para, plot = 'error')"]},{"cell_type":"code","source":["xgb_evaluation = predict_model(xgboost_para)\n","xgb_evaluation;"],"metadata":{"id":"MAR0zhLnmA7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IncNSYytrJCw"},"source":["## Light Gradient Boost"]},{"cell_type":"markdown","metadata":{"id":"mDEnoMOdWbMW"},"source":["From the table of model comparing above we could see that Light Gradient Boosting Machine gives the best result by inspect on MAE, RMSE and R2. So we should keep this model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfPUdNT9k-vm"},"outputs":[],"source":["lightgbm_para = create_model('lightgbm', round=2)\n","print(lightgbm_para)"]},{"cell_type":"markdown","metadata":{"id":"A4iLW8NNlZqX"},"source":["### Hyperparameter Tuning\n","Tunes the 'Light Gradient Boost' model. The output of this function is a score grid with CV scores by fold of the best selected model based on optimize parameter.\n","\n","[PyCaret: tune_model](https://pycaret.readthedocs.io/en/latest/api/regression.html#pycaret.regression.tune_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"boPPvY-ylFKp"},"outputs":[],"source":["tuned_lgb = tune_model(lightgbm_para)\n","print(tuned_lgb)"]},{"cell_type":"markdown","metadata":{"id":"5hKoXnW3Wt5o"},"source":["### Visualization\n","From the plot below, we know that the 'Light Gradient Boosting Machine' considers numerical variables (Living Space, Addition Cost, and No. of Rooms) more important than categorical variables (City, Heating Type, and Room Condition)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kCiy7RwlG9i"},"outputs":[],"source":["plot_model(tuned_lgb, plot='feature_all')"]},{"cell_type":"markdown","metadata":{"id":"RIN2975GWzj3"},"source":["Living Space, Addition Cost and Number of Rooms are the most important so we can make a conclusion that numerical are more important than catgorical variables for Light Gradient Boost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chfasm1_WHBh"},"outputs":[],"source":["plot_model(tuned_lgb, plot = 'error')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9_ujHfuWfPX"},"outputs":[],"source":["lgb_evaluation = predict_model(tuned_lgb)\n","lgb_evaluation;"]},{"cell_type":"markdown","metadata":{"id":"He_oBHBzrLwo"},"source":["## Linear Regression\n","Why not compare other models with Linear Regression? It's still the most straightforward model to understand, and we should look at how it decides to compare to LGBM."]},{"cell_type":"markdown","metadata":{"id":"lJu0xuZaQwu1"},"source":["Trains and evaluates the performance of a given estimator using cross validation.<br>\n","[PyCaret: create_model](https://pycaret.readthedocs.io/en/latest/api/regression.html#pycaret.regression.create_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYI91Ytpr4Li"},"outputs":[],"source":["lrm = create_model('lr')\n","print(lrm)"]},{"cell_type":"markdown","metadata":{"id":"REp3bYCIRfaK"},"source":["### Hyperparameter Tuning\n","Tunes the Linear Regression model. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyF7KYawX-dW"},"outputs":[],"source":["tuned_lr = tune_model(lrm)\n","print(tuned_lr)"]},{"cell_type":"markdown","metadata":{"id":"ZucsQnnNgK9R"},"source":["### Visualization\n","We could know from the plot that Linear Regression consider categorical variable more than numerical variables because it consider the city and room condition before others numerical variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKgGII6kYB5U"},"outputs":[],"source":["plot_model(tuned_lr, plot='feature_all')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ud2oW0YoWzkp"},"outputs":[],"source":["plot_model(tuned_lr, plot = 'error')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSvuJqMcXz_Z"},"outputs":[],"source":["lr_evaluation = predict_model(tuned_lr)\n","lr_evaluation;"]},{"cell_type":"markdown","metadata":{"id":"DjTM1CsJrQFt"},"source":["## Ridge Regression\n","Ridge Regression is always my favorite regression algorithm to predict the new datasets if we compare it with linear regression. I always used Ridge Regression because it will be optimized for prediction, so you could use a complex model and avoid overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Lxy2z2kYG9z"},"outputs":[],"source":["ridge_model = create_model('ridge')\n","print(ridge_model)"]},{"cell_type":"markdown","metadata":{"id":"Qc5Kz_Twllnt"},"source":["### Hyperparameter Tuning\n","Tunes the Ridge Regression model with higher number of iterations. I want to use Ridge Regression as our main predictor because it doesn't give bias or cause overfitting as Linear Regression\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbFyDxFFlJrI"},"outputs":[],"source":["tuned_ridge = tune_model(ridge_model)\n","print(tuned_ridge)"]},{"cell_type":"markdown","metadata":{"id":"hCOijl54gf8w"},"source":["### Visualization\n","From the plot below, Ridge Regression mostly worked like Linear Regression by being concerned with the categorical variables more than numerical variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60mkIbJulLkk"},"outputs":[],"source":["plot_model(tuned_ridge, plot='feature_all')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxUP2Q24XBc2"},"outputs":[],"source":["plot_model(tuned_ridge, plot = 'error')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTjFQ0ZPX4XN"},"outputs":[],"source":["ridge_evaluation = predict_model(tuned_ridge)\n","ridge_evaluation;"]},{"cell_type":"code","source":[],"metadata":{"id":"0I4TzmmW40KA"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}