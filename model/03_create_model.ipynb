{"cells":[{"cell_type":"markdown","id":"f5cd226a","metadata":{"papermill":{"duration":0.082908,"end_time":"2021-11-30T18:37:24.719827","exception":false,"start_time":"2021-11-30T18:37:24.636919","status":"completed"},"tags":[],"id":"f5cd226a"},"source":["# Germany Rental Prediction - Creating Model\n","\n","## Contents:\n","- Part 1: Cleaning and Visualization\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1biEgivJEOUVS8KbeTXyb1lNgsVtbitYj)\n","\n","- Part 2: Using PyCaret for Model Hyperparameters Tuning\n","  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lXJhdH3rGnKQ_LjBGMh8ZK-Lf2VcfLW5)\n","- Part 3: Create Model\n","  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14XIC90Lss_izdw-PE1cgIe4eECsXrHbY)\n"]},{"cell_type":"markdown","id":"c379ea48","metadata":{"papermill":{"duration":0.143421,"end_time":"2021-11-30T18:37:24.947230","exception":false,"start_time":"2021-11-30T18:37:24.803809","status":"completed"},"tags":[],"id":"c379ea48"},"source":["## Purpose from this notebook."]},{"cell_type":"markdown","id":"ba4af589","metadata":{"id":"ba4af589"},"source":["Creating the model base on '02_model_comparison_pycaret.ipynb' which has already done all the hyperparameters tuning by using PyCaret.\n","\n","We will create 2 models which are\n","1. Ridge Regression: [Wikipedia](https://en.wikipedia.org/wiki/Ridge_regression#:~:text=Ridge%20regression%20is%20a%20method,econometrics%2C%20chemistry%2C%20and%20engineering.)\n","2. Light Gradient Boostt: [Wikipedia](https://en.wikipedia.org/wiki/LightGBM)\n","3. Extreme Gradient Boost\n","4. CatBoost\n","5. Linear Regression\n","\n","and compare it by using the metrics such as R2 ([Coefficient of Determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)) and RMSE ([Root Mean Square Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) which is the standard matrix to measure the accuracy of the regression model. In addition, we will compare the speed of comparison to which model is much faster when you're using it as a prediction."]},{"cell_type":"markdown","id":"d7c5e3b8","metadata":{"papermill":{"duration":0.080428,"end_time":"2021-11-30T18:37:25.433063","exception":false,"start_time":"2021-11-30T18:37:25.352635","status":"completed"},"tags":[],"id":"d7c5e3b8"},"source":["# Basic data handling and inspection"]},{"cell_type":"markdown","id":"0f46b41d","metadata":{"papermill":{"duration":0.080623,"end_time":"2021-11-30T18:37:25.594471","exception":false,"start_time":"2021-11-30T18:37:25.513848","status":"completed"},"tags":[],"id":"0f46b41d"},"source":["Import all important libraries in this kernel"]},{"cell_type":"code","execution_count":null,"id":"b06aa3be","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:37:25.770296Z","iopub.status.busy":"2021-11-30T18:37:25.768447Z","iopub.status.idle":"2021-11-30T18:37:28.509566Z","shell.execute_reply":"2021-11-30T18:37:28.508883Z","shell.execute_reply.started":"2021-11-30T17:53:15.229572Z"},"papermill":{"duration":2.82814,"end_time":"2021-11-30T18:37:28.509742","exception":false,"start_time":"2021-11-30T18:37:25.681602","status":"completed"},"tags":[],"id":"b06aa3be"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import lightgbm as lgb\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","%matplotlib inline\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"markdown","id":"b1eaa2fa","metadata":{"papermill":{"duration":0.083271,"end_time":"2021-11-30T18:37:28.675681","exception":false,"start_time":"2021-11-30T18:37:28.592410","status":"completed"},"tags":[],"id":"b1eaa2fa"},"source":["Load the dataset to the kernel"]},{"cell_type":"code","execution_count":null,"id":"5976fc00","metadata":{"id":"5976fc00"},"outputs":[],"source":["!gdown --id 1yw4RN-Z9b7PlF45kC5HnXZokaXivk3EV\n","\n","df = pd.read_csv('predict_test.csv').iloc[:,1:]\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"41f025a4","metadata":{"id":"41f025a4"},"outputs":[],"source":["df[df['regio2']=='Berlin']"]},{"cell_type":"markdown","id":"847b792f","metadata":{"papermill":{"duration":0.37716,"end_time":"2021-11-30T18:38:40.271235","exception":false,"start_time":"2021-11-30T18:38:39.894075","status":"completed"},"tags":[],"id":"847b792f"},"source":["# Machine Learning"]},{"cell_type":"markdown","id":"3eecb5c6","metadata":{"papermill":{"duration":0.375223,"end_time":"2021-11-30T18:38:45.119958","exception":false,"start_time":"2021-11-30T18:38:44.744735","status":"completed"},"tags":[],"id":"3eecb5c6"},"source":["If it's an object or bool type (True,False). The code below will create the dummies for all of the categorical."]},{"cell_type":"code","execution_count":null,"id":"9fcebb6d","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:45.882667Z","iopub.status.busy":"2021-11-30T18:38:45.881242Z","iopub.status.idle":"2021-11-30T18:38:46.011476Z","shell.execute_reply":"2021-11-30T18:38:46.012029Z","shell.execute_reply.started":"2021-11-30T17:39:48.815171Z"},"papermill":{"duration":0.515827,"end_time":"2021-11-30T18:38:46.012220","exception":false,"start_time":"2021-11-30T18:38:45.496393","status":"completed"},"tags":[],"id":"9fcebb6d"},"outputs":[],"source":["# Create dummy variables\n","columns = []\n","for cols in df.columns:\n","    if df[cols].dtype == 'object' or df[cols].dtype == 'bool':\n","        columns.append(cols)\n","dummies_feature = pd.get_dummies(df[columns],prefix='',prefix_sep='')\n","dummies_feature.head()"]},{"cell_type":"markdown","id":"e9579999","metadata":{"papermill":{"duration":0.38109,"end_time":"2021-11-30T18:38:46.780579","exception":false,"start_time":"2021-11-30T18:38:46.399489","status":"completed"},"tags":[],"id":"e9579999"},"source":["Combine those columns together and drop the categorical columns that we created for the dummies."]},{"cell_type":"code","execution_count":null,"id":"9be8bba4","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:47.548701Z","iopub.status.busy":"2021-11-30T18:38:47.546553Z","iopub.status.idle":"2021-11-30T18:38:47.632697Z","shell.execute_reply":"2021-11-30T18:38:47.633303Z","shell.execute_reply.started":"2021-11-30T17:39:48.928925Z"},"papermill":{"duration":0.468945,"end_time":"2021-11-30T18:38:47.633488","exception":false,"start_time":"2021-11-30T18:38:47.164543","status":"completed"},"tags":[],"id":"9be8bba4"},"outputs":[],"source":["predict_df = df.copy()\n","predict_df = predict_df.drop(columns=columns)\n","predict_df = pd.concat([predict_df, dummies_feature], axis=1)\n","predict_df.head()"]},{"cell_type":"markdown","id":"dbfdd964","metadata":{"papermill":{"duration":0.378301,"end_time":"2021-11-30T18:38:50.048833","exception":false,"start_time":"2021-11-30T18:38:49.670532","status":"completed"},"tags":[],"id":"dbfdd964"},"source":["## Spliting the data into train and test"]},{"cell_type":"code","execution_count":null,"id":"6be3c000","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:50.810933Z","iopub.status.busy":"2021-11-30T18:38:50.809907Z","iopub.status.idle":"2021-11-30T18:38:50.986139Z","shell.execute_reply":"2021-11-30T18:38:50.985509Z","shell.execute_reply.started":"2021-11-30T17:39:49.044471Z"},"papermill":{"duration":0.561293,"end_time":"2021-11-30T18:38:50.986301","exception":false,"start_time":"2021-11-30T18:38:50.425008","status":"completed"},"tags":[],"id":"6be3c000"},"outputs":[],"source":["# Spliting the data into training and testing dataset\n","X = predict_df.iloc[:,1:] # Select all the columns, that's not totalRent\n","y = predict_df.iloc[:,0] # Select only totalRent\n","X_val = X.values\n","y_val = y.values\n","x_train, x_test, y_train, y_test = train_test_split(X_val, y_val, test_size = 0.10, random_state = 123)"]},{"cell_type":"code","execution_count":null,"id":"5f7f7cb7","metadata":{"scrolled":true,"id":"5f7f7cb7"},"outputs":[],"source":["print(f\"Number of train datasets: {x_train.shape[0]}\\n\")\n","print(f\"Number of test datasets: {x_test.shape[0]}\")"]},{"cell_type":"markdown","id":"fe2333b9","metadata":{"id":"fe2333b9"},"source":["## Ridge Regression\n","\n","Ridge regression is an example of a shrinkage method: in contrast to least squares, it reduces the parameter estimates in an effort to reduce variance, improve prediction accuracy, and simplify interpretation.\n"]},{"cell_type":"markdown","id":"c744d83b","metadata":{"id":"c744d83b"},"source":["### Setting hyperparameters and fit the model"]},{"cell_type":"code","execution_count":null,"id":"ec67e001","metadata":{"id":"ec67e001"},"outputs":[],"source":["from sklearn.linear_model import Ridge\n","ridge = Ridge(alpha=2.81, copy_X=True, fit_intercept=False, max_iter=None,\n","      normalize=True, random_state=123, solver='auto', tol=0.001)\n","\n","# Fit the data\n","ridge.fit(x_train,y_train)"]},{"cell_type":"code","execution_count":null,"id":"138d667f","metadata":{"id":"138d667f"},"outputs":[],"source":["# Predict in test dataset\n","\n","y_pred = ridge.predict(x_test)\n","y_pred"]},{"cell_type":"markdown","id":"f16d6006","metadata":{"id":"f16d6006"},"source":["### Create the Function to evaluate the model"]},{"cell_type":"code","execution_count":null,"id":"bc9e6673","metadata":{"id":"bc9e6673"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","\n","# Fill the dataframe variables in the dataset (x) and fill the target in target (y)\n","def evaluate_function(model,dataset,target,name): \n","    \"\"\"\n","    Create the function to evaluate the model by\n","    - model: Fill in the model that we've created before\n","    - dataset: The dataset that contains the feature or attribute\n","    - target: The label of the dataset\n","    - name: Fill in the name of the model\n","    \n","    and return into dictionary type for further use\n","    \"\"\"\n","    y_pred = model.predict(dataset)\n","\n","    print(f'Model name: {name}\\n')\n","    r2 = r2_score(target,y_pred)\n","    print(f'Coefficient of Determination (R2 score) of the model: {round(r2,3)}')\n","    rmse = pow(mean_squared_error(target,y_pred),0.5)\n","    print(f'RMSE (Root Mean Square Error) of the prediction: {round(rmse,3)}')\n","    mae = mean_absolute_error(target, y_pred)\n","    print(f'MAE (Mean Absolute Error) of the prediction: {round(mae,3)}')\n","    \n","    evaluation_results = {\"Model Name\": name,\n","                          'R2':r2,\n","                        'RMSE':rmse,\n","                        'MAE':mae}\n","    \n","    return evaluation_results\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5de79637","metadata":{"id":"5de79637"},"outputs":[],"source":["ridge_evaluation = evaluate_function(ridge,x_test,y_test,'Ridge Regression')"]},{"cell_type":"code","execution_count":null,"id":"7ebd5162","metadata":{"id":"7ebd5162"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","r2 = r2_score(y_test,y_pred)\n","print(f'Coefficient of Determination (r2_score): {r2}')\n","rms = pow(mean_squared_error(y_test,y_pred),0.5)\n","print(f'RMSE of the prediction: {rms}')"]},{"cell_type":"code","execution_count":null,"id":"020c22c6","metadata":{"id":"020c22c6"},"outputs":[],"source":["fig, ax = plt.subplots()\n","ax.scatter(y_pred,y_test,edgecolors=(0,0,1))\n","ax.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()], 'r--',\n","       lw=3)\n","ax.set_xlabel('Predicted')\n","ax.set_ylabel('Actual')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"38dd79e6","metadata":{"scrolled":true,"id":"38dd79e6"},"outputs":[],"source":["predict_df.head()"]},{"cell_type":"markdown","id":"d75d0fc7","metadata":{"id":"d75d0fc7"},"source":["### Create the Predict Function by using Ridge Regression Model"]},{"cell_type":"code","source":["from numpy import random\n","\n","def model_predict_price(model, df):\n","    random_data = df.iloc[random.randint(df.shape[0]-1),:]\n","\n","    heatingIndex = np.where(X.columns == random_data['heatingType'])[0][0]\n","    conIndex = np.where(X.columns == random_data['condition'])[0][0]\n","    flatTypeIndex = np.where(X.columns == random_data['typeOfFlat'])[0][0]\n","    regionIndex = np.where(X.columns == random_data['regio2'])[0][0]\n","\n","    x = np.zeros(len(X.columns))\n","    x[0] = random_data['livingSpace']\n","    x[1] = random_data['noRooms']\n","    x[2] = random_data['additioncost']\n","  \n","\n","    if heatingIndex >= 0:\n","        x[heatingIndex] = 1\n","    if conIndex >= 0:\n","        x[conIndex] = 1\n","    if flatTypeIndex >= 0:\n","        x[flatTypeIndex] = 1\n","    if regionIndex >= 0:\n","        x[regionIndex] = 1\n","\n","    predict_price = model.predict([x])[0]\n","    print(f\"Price from the dataframe: {random_data['totalRent']}\\nPrice from prediction :{predict_price}\")\n","\n","    return  predict_price"],"metadata":{"id":"5aAsYhLlFOVT"},"id":"5aAsYhLlFOVT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_price = model_predict_price(ridge, df)\n","print(predict_price)"],"metadata":{"id":"N70epa5K5jLY"},"id":"N70epa5K5jLY","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"71ecc3ae","metadata":{"id":"71ecc3ae"},"source":["## Create the function to compare randomly between the prediction and the dataset"]},{"cell_type":"code","execution_count":null,"id":"dd943570","metadata":{"id":"dd943570"},"outputs":[],"source":["def comparison(model, df):\n","    list_of_diff = [] # Create a list to calculate the average\n","    \n","    for i in range(0,20):\n","        random_data = df.iloc[random.randint(df.shape[0]-1),:]\n","\n","        heatingIndex = np.where(X.columns == random_data['heatingType'])[0][0]\n","        conIndex = np.where(X.columns == random_data['condition'])[0][0]\n","        flatTypeIndex = np.where(X.columns == random_data['typeOfFlat'])[0][0]\n","        regionIndex = np.where(X.columns == random_data['regio2'])[0][0]\n","\n","        x = np.zeros(len(X.columns))\n","        x[0] = random_data['livingSpace']\n","        x[1] = random_data['noRooms']\n","        x[2] = random_data['additioncost']\n","      \n","\n","        if heatingIndex >= 0:\n","            x[heatingIndex] = 1\n","        if conIndex >= 0:\n","            x[conIndex] = 1\n","        if flatTypeIndex >= 0:\n","            x[flatTypeIndex] = 1\n","        if regionIndex >= 0:\n","            x[regionIndex] = 1\n","\n","        predict_price = model.predict([x])[0]\n","        diff = abs(random_data['totalRent']-predict_price)\n","        print(f\"{i:<5}: Dataframe: {random_data['totalRent']:<10},  Model Prediction : {round(predict_price,2):<10},  Difference: {round(diff,2)}\")\n","\n","        \n","        # add the number of difference value of train and test to the list\n","        list_of_diff.append(diff) \n","        # print(\"\\n======================\\n\")\n","    \n","    avg = sum(list_of_diff)/len(list_of_diff)\n","    print(\"\\n======================\")\n","    print(f\"\\nThe average of the difference from the actual and prediction: {avg}\")"]},{"cell_type":"markdown","id":"f10ea049","metadata":{"id":"f10ea049"},"source":["### Testing the data randomly by using comparison function"]},{"cell_type":"code","execution_count":null,"id":"fc66f891","metadata":{"id":"fc66f891"},"outputs":[],"source":["comparison(ridge, df)"]},{"cell_type":"markdown","id":"b1bdb420","metadata":{"papermill":{"duration":0.378833,"end_time":"2021-11-30T18:38:51.746066","exception":false,"start_time":"2021-11-30T18:38:51.367233","status":"completed"},"tags":[],"id":"b1bdb420"},"source":["## Light Gradient Boost"]},{"cell_type":"markdown","id":"dfa18785","metadata":{"id":"dfa18785"},"source":["### Setting hyperparameters and fit the model"]},{"cell_type":"code","execution_count":null,"id":"2fcdfe62","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:52.540064Z","iopub.status.busy":"2021-11-30T18:38:52.539361Z","iopub.status.idle":"2021-11-30T18:40:09.544507Z","shell.execute_reply":"2021-11-30T18:40:09.543831Z","shell.execute_reply.started":"2021-11-30T17:39:49.202062Z"},"papermill":{"duration":77.396535,"end_time":"2021-11-30T18:40:09.544662","exception":false,"start_time":"2021-11-30T18:38:52.148127","status":"completed"},"tags":[],"id":"2fcdfe62"},"outputs":[],"source":["d_train = lgb.Dataset(x_train, label=y_train) # Load the dataset and test\n","\n","# parameters for this model\n","params = {\n","        'n_estimators': 10000,\n","        'objective': 'regression',\n","        'metric': 'rmse',\n","        'boosting_type': 'gbdt',\n","        'max_depth': -1,\n","        'learning_rate': 0.01,\n","        'subsample': 0.72,\n","        'subsample_freq': 4,\n","        'feature_fraction': 0.4,\n","        'lambda_l1': 1,\n","        'lambda_l2': 1,\n","        'seed': 46,\n","        }\n","\n","lightgb = lgb.train(params, d_train, 100)"]},{"cell_type":"markdown","id":"d9a9eb5d","metadata":{"papermill":{"duration":0.378492,"end_time":"2021-11-30T18:40:10.307219","exception":false,"start_time":"2021-11-30T18:40:09.928727","status":"completed"},"tags":[],"id":"d9a9eb5d"},"source":["Check the data is what'we expected or not."]},{"cell_type":"code","execution_count":null,"id":"6622d597","metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:40:11.081260Z","iopub.status.busy":"2021-11-30T18:40:11.077227Z","iopub.status.idle":"2021-11-30T18:40:38.827911Z","shell.execute_reply":"2021-11-30T18:40:38.828626Z","shell.execute_reply.started":"2021-11-30T17:41:01.436815Z"},"papermill":{"duration":28.139326,"end_time":"2021-11-30T18:40:38.829158","exception":false,"start_time":"2021-11-30T18:40:10.689832","status":"completed"},"tags":[],"id":"6622d597"},"outputs":[],"source":["y_pred = lightgb.predict(x_test)\n","y_pred"]},{"cell_type":"markdown","id":"5a4a6bec","metadata":{"papermill":{"duration":0.386891,"end_time":"2021-11-30T18:42:22.541039","exception":false,"start_time":"2021-11-30T18:42:22.154148","status":"completed"},"tags":[],"id":"5a4a6bec"},"source":["The result of the 'Light Gradient Boosting Machine' is working great and we could use this model in concern of accuracy if compare with the 'Ridge Regression'"]},{"cell_type":"code","execution_count":null,"id":"ae202f6c","metadata":{"id":"ae202f6c"},"outputs":[],"source":["lightgb_evaluation = evaluate_function(lightgb,x_test,y_test,'Light Gradient Boost')\n","lightgb_evaluation"]},{"cell_type":"markdown","id":"66b8762e","metadata":{"id":"66b8762e"},"source":["### Testing the data randomly by using comparison function"]},{"cell_type":"code","source":["comparison(lightgb, df)"],"metadata":{"id":"R-BKGbgHHp_Y"},"id":"R-BKGbgHHp_Y","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"194946b5","metadata":{"id":"194946b5"},"source":["Let's try some rows to make sure our models is working properly"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.378833,"end_time":"2021-11-30T18:38:51.746066","exception":false,"start_time":"2021-11-30T18:38:51.367233","status":"completed"},"tags":[],"id":"6Vvgh8OY8hW3"},"source":["## Catboost"],"id":"6Vvgh8OY8hW3"},{"cell_type":"markdown","metadata":{"id":"A5OmUFVV8hW9"},"source":["### Setting hyperparameters and fit the model"],"id":"A5OmUFVV8hW9"},{"cell_type":"code","source":["!pip install catboost\n","import catboost as cb"],"metadata":{"id":"96wdHy9I9C-6"},"id":"96wdHy9I9C-6","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:52.540064Z","iopub.status.busy":"2021-11-30T18:38:52.539361Z","iopub.status.idle":"2021-11-30T18:40:09.544507Z","shell.execute_reply":"2021-11-30T18:40:09.543831Z","shell.execute_reply.started":"2021-11-30T17:39:49.202062Z"},"papermill":{"duration":77.396535,"end_time":"2021-11-30T18:40:09.544662","exception":false,"start_time":"2021-11-30T18:38:52.148127","status":"completed"},"tags":[],"id":"H_gkZnq68hW-"},"outputs":[],"source":["train_dataset = cb.Pool(x_train, y_train)\n","test_dataset = cb.Pool(x_test, y_test)"],"id":"H_gkZnq68hW-"},{"cell_type":"code","source":["catboost = cb.CatBoostRegressor(loss_function=\"RMSE\")"],"metadata":{"id":"_620OsPy8hW-"},"id":"_620OsPy8hW-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid = {'iterations': [100, 150, 200],\n","        'learning_rate': [0.03, 0.1],\n","        'depth': [2, 4, 6, 8],\n","        'l2_leaf_reg': [0.2, 0.5, 1, 3]}\n","catboost.grid_search(grid, train_dataset)"],"metadata":{"id":"2Aczccu89sRm"},"id":"2Aczccu89sRm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_preds = catboost.predict(x_test)\n","y_preds"],"metadata":{"id":"JzEpoiGj-NUh"},"id":"JzEpoiGj-NUh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["catboost_evaluation = evaluate_function(catboost,x_test,y_test,'CatBoost')\n"],"metadata":{"id":"ywgfFQHYNLiv"},"id":"ywgfFQHYNLiv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison(catboost, df)"],"metadata":{"id":"tF7zH-p2_qRX"},"id":"tF7zH-p2_qRX","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.378833,"end_time":"2021-11-30T18:38:51.746066","exception":false,"start_time":"2021-11-30T18:38:51.367233","status":"completed"},"tags":[],"id":"rOV0xAshNqPv"},"source":["## Xgboost"],"id":"rOV0xAshNqPv"},{"cell_type":"markdown","metadata":{"id":"9Vy_l08pNqPv"},"source":["### Setting hyperparameters and fit the model"],"id":"9Vy_l08pNqPv"},{"cell_type":"code","source":["import xgboost\n","from xgboost import XGBRegressor"],"metadata":{"id":"QVgSM2ywNqPv"},"execution_count":null,"outputs":[],"id":"QVgSM2ywNqPv"},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:52.540064Z","iopub.status.busy":"2021-11-30T18:38:52.539361Z","iopub.status.idle":"2021-11-30T18:40:09.544507Z","shell.execute_reply":"2021-11-30T18:40:09.543831Z","shell.execute_reply.started":"2021-11-30T17:39:49.202062Z"},"papermill":{"duration":77.396535,"end_time":"2021-11-30T18:40:09.544662","exception":false,"start_time":"2021-11-30T18:38:52.148127","status":"completed"},"tags":[],"id":"agzV4oRfNqPw"},"outputs":[],"source":["xgboost = XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n","             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n","             early_stopping_rounds=None, enable_categorical=False,\n","             eval_metric=None, gamma=0, grow_policy='depthwise',\n","             importance_type=None, interaction_constraints='',\n","             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n","             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n","             n_estimators=100, n_jobs=-1, num_parallel_tree=1, objective='reg:squarederror',\n","             random_state=123)\n","xgboost = xgboost.fit(x_train, y_train)"],"id":"agzV4oRfNqPw"},{"cell_type":"code","source":["y_preds = xgboost.predict(x_test)\n","y_preds"],"metadata":{"id":"66aMpXyfNqPw"},"execution_count":null,"outputs":[],"id":"66aMpXyfNqPw"},{"cell_type":"code","source":["xgboost_evaluation = evaluate_function(xgboost,x_test,y_test,'Xgboost')"],"metadata":{"id":"3eY5pgWUNqPw"},"execution_count":null,"outputs":[],"id":"3eY5pgWUNqPw"},{"cell_type":"code","source":["comparison(xgboost, df)"],"metadata":{"id":"bAD9NJEtNqPw"},"execution_count":null,"outputs":[],"id":"bAD9NJEtNqPw"},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.378833,"end_time":"2021-11-30T18:38:51.746066","exception":false,"start_time":"2021-11-30T18:38:51.367233","status":"completed"},"tags":[],"id":"d_7Wgemnfqf8"},"source":["## Linear Regression"],"id":"d_7Wgemnfqf8"},{"cell_type":"markdown","metadata":{"id":"VbErIAnPfqgI"},"source":["### Setting hyperparameters and fit the model"],"id":"VbErIAnPfqgI"},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression"],"metadata":{"id":"Jw4fUQtjfqgK"},"execution_count":null,"outputs":[],"id":"Jw4fUQtjfqgK"},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-30T18:38:52.540064Z","iopub.status.busy":"2021-11-30T18:38:52.539361Z","iopub.status.idle":"2021-11-30T18:40:09.544507Z","shell.execute_reply":"2021-11-30T18:40:09.543831Z","shell.execute_reply.started":"2021-11-30T17:39:49.202062Z"},"papermill":{"duration":77.396535,"end_time":"2021-11-30T18:40:09.544662","exception":false,"start_time":"2021-11-30T18:38:52.148127","status":"completed"},"tags":[],"id":"HclrCHZQfqgK"},"outputs":[],"source":["linear = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n","linear = linear.fit(x_train, y_train)"],"id":"HclrCHZQfqgK"},{"cell_type":"code","source":["y_preds = linear.predict(x_test)\n","y_pred[0:100]"],"metadata":{"id":"PqD9eyVEfqgK"},"execution_count":null,"outputs":[],"id":"PqD9eyVEfqgK"},{"cell_type":"code","source":["linear_evaluation = evaluate_function(linear,x_test,y_test,'Linear Regression')"],"metadata":{"id":"dFa0HKQpfqgL"},"execution_count":null,"outputs":[],"id":"dFa0HKQpfqgL"},{"cell_type":"markdown","id":"3d480649","metadata":{"id":"3d480649"},"source":["# Comparison between models"]},{"cell_type":"code","execution_count":null,"id":"44c53de2","metadata":{"id":"44c53de2"},"outputs":[],"source":["ridge_evaluation"]},{"cell_type":"code","execution_count":null,"id":"6987a0a1","metadata":{"id":"6987a0a1"},"outputs":[],"source":["# Create comparison dataframe from our past dictionary\n","comparison = pd.DataFrame({ridge_evaluation['Model Name']:ridge_evaluation,\n","                           lightgb_evaluation['Model Name']:lightgb_evaluation,\n","                           catboost_evaluation['Model Name']:catboost_evaluation,\n","                           xgboost_evaluation['Model Name']:xgboost_evaluation,\n","                           linear_evaluation['Model Name']:linear_evaluation})\n","\n","\n","comparison = comparison.transpose()\n","comparison.reset_index(drop=True)"]},{"cell_type":"markdown","id":"850d0903","metadata":{"id":"850d0903"},"source":["## Accuracy of the model"]},{"cell_type":"code","execution_count":null,"id":"190b2980","metadata":{"id":"190b2980"},"outputs":[],"source":["comparison[['RMSE','MAE']].sort_values('RMSE',ascending=False).plot(kind='bar',figsize=(10,10)).legend(bbox_to_anchor=(1.0,1.0))"]},{"cell_type":"markdown","id":"c27d6a7c","metadata":{"id":"c27d6a7c"},"source":["## The speed/score tradeoff"]},{"cell_type":"markdown","id":"c84283db","metadata":{"id":"c84283db"},"source":["### Create the function to measure the time of prediction"]},{"cell_type":"code","execution_count":null,"id":"ddfccd91","metadata":{"id":"ddfccd91"},"outputs":[],"source":["import time\n","def pred_timer(model,samples):\n","    start_time = time.perf_counter()\n","    model.predict(samples)\n","    end_time = time.perf_counter()\n","    total_time = end_time-start_time\n","    time_per_pred = total_time/len(samples)\n","    return total_time, time_per_pred"]},{"cell_type":"markdown","id":"99d86f47","metadata":{"id":"99d86f47"},"source":["Calcuate the Ridge Regression time per prediction"]},{"cell_type":"code","source":["x_test.shape"],"metadata":{"id":"W9oFm8Tdrree"},"id":"W9oFm8Tdrree","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b745256b","metadata":{"id":"b745256b"},"outputs":[],"source":["total_pred_time_ridge_reg, time_per_pred_ridge_reg = pred_timer(ridge,x_test)\n","\n","print('Ridge Regression Model')\n","print(f\"Total time prediction for test dataframe: {round(total_pred_time_ridge_reg,3)}\")\n","print(f\"Time per each prediction: {round(time_per_pred_ridge_reg,10)}\")\n"]},{"cell_type":"markdown","id":"0974ffae","metadata":{"id":"0974ffae"},"source":["Calculate the Light Gradient Boost time per prediction"]},{"cell_type":"code","execution_count":null,"id":"174e7cd7","metadata":{"id":"174e7cd7"},"outputs":[],"source":["total_pred_time_lgbm, time_per_pred_lgbm = pred_timer(lightgb,x_test)\n","\n","print(\"Light Gradient Boost Model\")\n","print(f\"Total time prediction for test dataframe: {round(total_pred_time_lgbm,3)} seconds\")\n","print(f\"Time per each prediction: {round(time_per_pred_lgbm,10)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"UQxYq29fQNcE"},"source":["Calculate the CatBoost time per prediction"],"id":"UQxYq29fQNcE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvGfZLYjQNcE"},"outputs":[],"source":["total_pred_time_catboost, time_per_pred_catboost = pred_timer(catboost,x_test)\n","\n","print(\"Light Gradient Boost Model\")\n","print(f\"Total time prediction for test dataframe: {round(total_pred_time_catboost,3)} seconds\")\n","print(f\"Time per each prediction: {round(time_per_pred_catboost,10)}\")\n"],"id":"fvGfZLYjQNcE"},{"cell_type":"markdown","metadata":{"id":"YFlCnbEZQOjb"},"source":["Calculate the XgBoost time per prediction"],"id":"YFlCnbEZQOjb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVWiEXtCQOjf"},"outputs":[],"source":["total_pred_time_xgboost, time_per_pred_xgboost = pred_timer(xgboost,x_test)\n","\n","print(\"Light Gradient Boost Model\")\n","print(f\"Total time prediction for test dataframe: {round(total_pred_time_xgboost,3)} seconds\")\n","print(f\"Time per each prediction: {round(time_per_pred_xgboost,10)}\")\n"],"id":"hVWiEXtCQOjf"},{"cell_type":"markdown","metadata":{"id":"9nASleZbmTDk"},"source":["Calculate the Linear Regression time per prediction"],"id":"9nASleZbmTDk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cqGcVq6mTDp"},"outputs":[],"source":["total_pred_time_linear, time_per_pred_linear = pred_timer(linear,x_test)\n","\n","print(\"Linear Regression Model\")\n","print(f\"Total time prediction for test dataframe: {round(total_pred_time_linear,3)} seconds\")\n","print(f\"Time per each prediction: {round(time_per_pred_linear,10)}\")\n"],"id":"3cqGcVq6mTDp"},{"cell_type":"code","execution_count":null,"id":"0c755050","metadata":{"id":"0c755050"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10,10))\n","plt.scatter(time_per_pred_ridge_reg, ridge_evaluation['RMSE'], s=200, label=\"Ridge Regression\")\n","plt.scatter(time_per_pred_lgbm, lightgb_evaluation['RMSE'], s=200,  label=\"Light Gradient Boost\")\n","plt.scatter(time_per_pred_catboost, catboost_evaluation['RMSE'], s=200, label=\"Catboost\")\n","plt.scatter(time_per_pred_xgboost, xgboost_evaluation['RMSE'], s=200, label=\"Xgboost\")\n","plt.text(x=0.00003, y=121.5, s=\"Best Model: Xgboost\", size=20)\n","plt.scatter(time_per_pred_linear, linear_evaluation['RMSE'], s=200, c=\"black\", label=\"Linear Regression\")\n","plt.scatter(0.00001,118, s=200, label=\"Ideal model\")\n","plt.text(x=0.00003, y=118, s=\"Ideal regression model\", size=20)\n","\n","plt.legend(prop={'size': 16})\n","plt.title(\"Comparison between RMSE and time per prediction\")\n","plt.xlabel(\"Time per prediction\")\n","plt.ylabel(\"RMSE\")"]},{"cell_type":"markdown","id":"3bf047a6","metadata":{"id":"3bf047a6"},"source":["## Conclusion"]},{"cell_type":"markdown","id":"0767d5a6","metadata":{"id":"0767d5a6"},"source":["\\\\From the plot above we could see that Xgboost Regressor might have slightly error compare to Light Gradient Boost Machine but the time is much faster. Then if you want the model that is has a better prediction 'Light Gradient Boost Machine' might be better answer. However, if you're concern of speed, 'Ridge Regression' has 10 times better in speed.\n","\n","I would use 'Xgboost' to predict the price afterward due to the resources and the scope of my work is limited."]},{"cell_type":"markdown","id":"0bd8d951","metadata":{"id":"0bd8d951"},"source":["# Saving the model for further use."]},{"cell_type":"code","execution_count":null,"id":"26ff1e05","metadata":{"id":"26ff1e05"},"outputs":[],"source":["import pickle\n","with open('german_home_prices_model.pickle','wb') as f:\n","    pickle.dump(xgboost,f)"]},{"cell_type":"code","execution_count":null,"id":"754b7de3","metadata":{"id":"754b7de3"},"outputs":[],"source":["import json\n","columns = {\n","    'data_columns' : [col.lower() for col in X.columns]\n","}\n","with open(\"columns.json\",\"w\") as f:\n","    f.write(json.dumps(columns))"]},{"cell_type":"markdown","id":"28994917","metadata":{"papermill":{"duration":0.38576,"end_time":"2021-11-30T18:42:23.311319","exception":false,"start_time":"2021-11-30T18:42:22.925559","status":"completed"},"tags":[],"id":"28994917"},"source":["# Summary"]},{"cell_type":"markdown","id":"f5ba7b49","metadata":{"papermill":{"duration":0.385744,"end_time":"2021-11-30T18:42:24.081096","exception":false,"start_time":"2021-11-30T18:42:23.695352","status":"completed"},"tags":[],"id":"f5ba7b49"},"source":["This is the end of the kernel, if you love this kernel or could study something from this please upvote! it means a lot for my future opportunity. Moreover, feel free to comment on my mistakes because it would be surely help me to improve my mistakes.\n","\n","Thanks for viewing!"]}],"metadata":{"interpreter":{"hash":"9b6558af67744e838d8043107d7139df75d7e44c9db2e97384ca8749d628ea25"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"papermill":{"default_parameters":{},"duration":310.867847,"end_time":"2021-11-30T18:42:25.683424","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-11-30T18:37:14.815577","version":"2.3.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"274px"},"toc_section_display":true,"toc_window_display":true},"colab":{"provenance":[],"private_outputs":true},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}